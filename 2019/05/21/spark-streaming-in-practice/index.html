<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Spark Streaming in Practice（一）——读写kafka之写Kafka | Silence Fly</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="记录Spark Streaming开发中的一些经验，有些是在当前理解下的个人总结，可能有失偏颇。无特别说明，下文中Spark 指Spark Streaming 应用。spark Streaming支持很多数据源，如file、socket但无疑Kakfa是其中最重要的streaming数据源，本文会对其重点研究研究。这一块基本思路是，首先看一下Kafka提供的基本的数据读写的API，然后再看一下Sp">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark Streaming in Practice（一）——读写kafka之写Kafka">
<meta property="og:url" content="http://example.com/2019/05/21/spark-streaming-in-practice/index.html">
<meta property="og:site_name" content="Silence Fly">
<meta property="og:description" content="记录Spark Streaming开发中的一些经验，有些是在当前理解下的个人总结，可能有失偏颇。无特别说明，下文中Spark 指Spark Streaming 应用。spark Streaming支持很多数据源，如file、socket但无疑Kakfa是其中最重要的streaming数据源，本文会对其重点研究研究。这一块基本思路是，首先看一下Kafka提供的基本的数据读写的API，然后再看一下Sp">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://kafka.apache.org/images/log_anatomy.png">
<meta property="article:published_time" content="2019-05-21T00:32:49.000Z">
<meta property="article:modified_time" content="2021-05-07T08:27:05.228Z">
<meta property="article:author" content="郭鹏飞">
<meta property="article:tag" content="spark">
<meta property="article:tag" content="streaming">
<meta property="article:tag" content="实践">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://kafka.apache.org/images/log_anatomy.png">
  
    <link rel="alternate" href="/atom.xml" title="Silence Fly" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Silence Fly</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS 订阅"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-spark-streaming-in-practice" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/05/21/spark-streaming-in-practice/" class="article-date">
  <time class="dt-published" datetime="2019-05-21T00:32:49.000Z" itemprop="datePublished">2019-05-21</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/">技术实践</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Spark Streaming in Practice（一）——读写kafka之写Kafka
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>记录Spark Streaming开发中的一些经验，有些是在当前理解下的个人总结，可能有失偏颇。无特别说明，下文中Spark 指Spark Streaming 应用。spark Streaming支持很多数据源，如file、socket但无疑Kakfa是其中最重要的streaming数据源，本文会对其重点研究研究。这一块基本思路是，首先看一下Kafka提供的基本的数据读写的API，然后再看一下Spark对相关API进一步封装提供了哪些功能。</p>
<span id="more"></span>

<h2 id="Kafka-基本概念"><a href="#Kafka-基本概念" class="headerlink" title="Kafka 基本概念"></a>Kafka 基本概念</h2><p>kafka是一个分布式的消息队列，即可以有生产者和消费者分别发布和订阅消息，kafka对消息进行持久化缓存，以使得生产者和消费者可以异步通信，并支持多个消费者复用消息。就像一个水池，可以有多个上游往水池中注水，也可以有多个下游从水池中取水。</p>
<ul>
<li>数据记录：每条数据记录由 key、 value和 timestamp组成。</li>
<li>kafka Broker: kafka由一到多个server组成，每个server称为Broker；每台机器上可以有一到多个broker，一组broker由zookeeper连接起来组成一个kafka集群。  Client(consumer或producer)和server(broker)通过<strong>TCP</strong>协议通信。</li>
<li>Topic：kafka定义Topic的概念来提升消息队列的并行度，即从应用上可以认为每个Topic是一个单独的消息队列。</li>
<li>Partition：像大多数分布式系统一样，kafka引入Partition(分区)来通过并行执行来提升性能（吞吐等），每个Topic会划分为多个partition，不同的partition分配给不同的broker来处理，所以Broker和Partition是多对多的关系。<strong>Produer 可以决定消息的分区规则，来分配到指定的partition</strong>。 注意：consumer的数量不能比partitions多（相同的consumer group），最多只会有partitions个consumer消费数据。</li>
<li>Replica（副本）: 像大多数分布式系统一样，kafka引入多副本(Replica)来提升系统容错性，即每个partition会有多个副本，遇到故障时保证还有备份数据可用。<strong>每个partition有一个broker作为leader还有0到多个broker作为follower。此处，kafka采用冷备机制，即leader提供数据的读写，follower只是被动的备份数据，只在leader出现故障时，从多个follower中选出新的leader。注意：因为对于不同的broker可以是不同的partition的leader，所以从整体上达到负载均衡的作用，即每个broker都有成为leader提供数据读写的机会</strong></li>
<li>offset：Partition中的每条Message由offset来表示它在这个partition中的偏移量，这个offset不是该Message在partition数据文件中的实际存储位置，而是逻辑上一个值，它唯一确定了partition中的一条Message。因此，可以认为offset是partition中Message的id。实际上，offset是kafka中唯一的元数据。</li>
<li>关于数据顺序：kafka只能保证数据在单个partition内是有序的。若只有一个consumer，则能保证Topic级别的有序。</li>
<li>持久化：kafka会按照设定的生命期缓存所有的消息，其使用文件存储消息(append only log)，为了减少磁盘写入的次数，broker会将消息暂时缓存在内存中，当消息的个数(或尺寸)达到一定阀值时，再flush到磁盘。</li>
<li>Segment：为了提升消息随机读的性能，kafka将数据文件分割为较小的segment。并通过索引来提升数据查询的性能，索引文件记录了offset对应的文件及具体位置。为了减少存储，offset存储的是相对于第一个offset的相对便宜，并没有存储所有offset的索引，而是有一定间隔的稀疏索引。</li>
<li>Consumer Group：在kafka中实际的订阅单位其实是consumer group，即每个Topic中的每条记录只会被一个consumer group消费一次。ps:同一个group中的多个consumer可以在不同的机器上。</li>
</ul>
<p><img src="http://kafka.apache.org/images/log_anatomy.png" alt="img"></p>
<h2 id="Kafka-0-8-Vs-0-10"><a href="#Kafka-0-8-Vs-0-10" class="headerlink" title="Kafka 0.8 Vs. 0.10"></a>Kafka 0.8 Vs. 0.10</h2><p>0.10 adds the following over 0.8</p>
<ul>
<li>Zookeeper connections are discouraged . From 0.10 there won’t be any zookeeper connections required . All connections for consuming data will be maintained by consumer API</li>
<li>new unified Consumer API</li>
<li>reduced client dependence on zookeeper (offsets stored in Kafka topic)</li>
<li>Kafka Streams API</li>
<li>Kafka Connect API</li>
<li>transport encryption using TLS/SSL</li>
<li>Kerberos/SASL Authentication support</li>
<li>Access Control Lists</li>
<li>timestamps on messages</li>
<li>client interceptors</li>
<li>lots and lots of bug fixes and improvements</li>
</ul>
<p>从上，我们可以看出，0.10版本在0.8版本的基础上除了扩充功能，<strong>主要是对consumer API的重构</strong>。</p>
<h2 id="Kakfa-Producer-API"><a href="#Kakfa-Producer-API" class="headerlink" title="Kakfa Producer API"></a>Kakfa Producer API</h2><p>Producer API有如下特性：</p>
<ol>
<li>有同步和异步两种数据处理方式，用配置producer.type=async/sync来区分，默认是sync。其中异步方式会将数据进行缓存，直到达到缓存时间阈值或batch大小阈值才会进行发送；</li>
<li>用户自定义数据分区函数；</li>
<li>用户自定义数据序列化接口；</li>
</ol>
<p>在<strong>Kafka 0.8.0 官网文档</strong>上说 可以使用zookeeper来支持 broker的发现，但是在<strong>0.8.0 Producer Example</strong> 文档中，又推荐使用的是<strong>metadata.broker.list</strong> 参数。</p>


<p>经测试验证，应该使用<strong>metadata.broker.list</strong> 否则会报缺少参数。 </p>
<p>配置的时候不需要配置所有的brokerlist，只需要配置两个(容错)就可以了，kafka会自动做负载均衡，选出合适的leader。</p>
<h2 id="Spark-写Kafka"><a href="#Spark-写Kafka" class="headerlink" title="Spark 写Kafka"></a>Spark 写Kafka</h2><p>spark streaming/spark写Kafka的一个可行方法是，对每个executor 调用创建Kafka Producer 客户端，各分区单独发送数据，样例大体结构如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">result.foreachRDD&#123;rdd=&gt;</span><br><span class="line">  rdd.foreachPartition&#123; iter=&gt;</span><br><span class="line">    <span class="comment">// 调用kafka Producer 发送数据</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>但需要注意Producer 实例尽量复用，以提升性能。</p>
<p>Cloudera封装好了一个工具帮我们完成该过程，(原始代码已经找不到，是否复用Producer实例未验证)，该工具其实是从 <a target="_blank" rel="noopener" href="https://issues.apache.org/jira/browse/SPARK-4122">Jira-4-22</a> 拆分出来的。Maven坐标如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.cloudera.spark.streaming.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-kafka-writer<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>0.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>从<a target="_blank" rel="noopener" href="https://mvnrepository.com/artifact/org.cloudera.spark.streaming.kafka/spark-kafka-writer">MavenPository</a> 中看到，最新的版本还是0.1.0，更新日期是 2015年，不确定是有更好的方案还是什么原因，造成该工具一直没有升级。</p>




<p>源码：<a target="_blank" rel="noopener" href="https://github.com/harishreedharan/spark-streaming-kafka-output">https://github.com/harishreedharan/spark-streaming-kafka-output</a></p>
<p>ps: 该项目描述中标注了 “Move to org.cloudera “，所以这很大的可能性是该工具的源码。从代码可以看到，其实现跟上述分析的方案一致。</p>
<p>如下代码样例，该工具封装了隐式转换，导入后DStream类型会添加 <em>writeToKafka</em> 函数，并且用户自己添加自定义的<strong>分区函数</strong>。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.cloudera.spark.streaming.kafka.<span class="type">KafkaWriter</span>._</span><br><span class="line"></span><br><span class="line">stream.writeToKafka(producerConf,</span><br><span class="line">            (x: <span class="type">String</span>) =&gt; <span class="keyword">new</span> <span class="type">KeyedMessage</span>[<span class="type">String</span>, <span class="type">String</span>](topic,<span class="type">DigestUtils</span>.md5Hex(x), x))</span><br></pre></td></tr></table></figure>



<p>kafka的config会透传下去，到kafka原生Producer API。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/seaspring/p/6138080.html">Kafka：架构简介【转】</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/yurunmiao/p/5550906.html">Kafka Topic Partition Replica Assignment实现原理及资源隔离方案</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="http://kafka.apache.org/08/documentation.html">Kafka 0.8.0 官网文档</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+Producer+Example">0.8.0 Producer Example</a></p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/05/21/spark-streaming-in-practice/" data-id="ckoe220c3000nqw926d3mbd0g" data-title="Spark Streaming in Practice（一）——读写kafka之写Kafka" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/" rel="tag">spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/streaming/" rel="tag">streaming</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%AE%9E%E8%B7%B5/" rel="tag">实践</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/05/21/spark-streaming-in-practice-2/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">前一篇</strong>
      <div class="article-nav-title">
        
          Spark Streaming in Practice（二）——读写kafka之读Kafka
        
      </div>
    </a>
  
  
    <a href="/2019/05/15/Spark%E5%AD%98%E5%82%A8%E4%BD%93%E7%B3%BB%E8%AF%A6%E8%A7%A3/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">后一篇</strong>
      <div class="article-nav-title">Spark存储体系详解</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/">技术原理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5/">技术实践</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BB%BC%E5%90%88%E8%83%BD%E5%8A%9B/">综合能力</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/">编程基础</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/LeetCode/" rel="tag">LeetCode</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OKR/" rel="tag">OKR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flink/" rel="tag">flink</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/" rel="tag">spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/streaming/" rel="tag">streaming</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%9E%E8%B7%B5/" rel="tag">实践</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%BA%90%E7%A0%81/" rel="tag">源码</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/LeetCode/" style="font-size: 10px;">LeetCode</a> <a href="/tags/OKR/" style="font-size: 10px;">OKR</a> <a href="/tags/flink/" style="font-size: 10px;">flink</a> <a href="/tags/spark/" style="font-size: 20px;">spark</a> <a href="/tags/streaming/" style="font-size: 15px;">streaming</a> <a href="/tags/%E5%AE%9E%E8%B7%B5/" style="font-size: 15px;">实践</a> <a href="/tags/%E6%BA%90%E7%A0%81/" style="font-size: 15px;">源码</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 10px;">算法</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">六月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">五月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/11/04/Spark0-1-rdd-and-task-schedule/">Spark0.1源码学习之-编程模型和任务调度</a>
          </li>
        
          <li>
            <a href="/2019/06/30/okr-introduction/">OKR简介</a>
          </li>
        
          <li>
            <a href="/2019/05/24/leetcode-summary/">CleanHandBook (LeetCode) summary</a>
          </li>
        
          <li>
            <a href="/2019/05/21/spark-streaming-in-practice-2/">Spark Streaming in Practice（二）——读写kafka之读Kafka</a>
          </li>
        
          <li>
            <a href="/2019/05/21/spark-streaming-in-practice/">Spark Streaming in Practice（一）——读写kafka之写Kafka</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 郭鹏飞<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>